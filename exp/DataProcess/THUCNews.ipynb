{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2f8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bb692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾æ ·å¼\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Microsoft YaHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾\n",
    "plt.rcParams['axes.unicode_minus'] = False    # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06358c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'data/THUCNews/cnews.train.txt',\n",
       " 'val': 'data/THUCNews/cnews.val.txt',\n",
       " 'test': 'data/THUCNews/cnews.test.txt',\n",
       " 'vocab': 'data/THUCNews/cnews.vocab.txt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/THUCNews\"\n",
    "\n",
    "files = {\n",
    "    'train': os.path.join(data_dir, 'cnews.train.txt'),\n",
    "    'val': os.path.join(data_dir, 'cnews.val.txt'),\n",
    "    'test': os.path.join(data_dir, 'cnews.test.txt'),\n",
    "    'vocab': os.path.join(data_dir, 'cnews.vocab.txt')\n",
    "}\n",
    "\n",
    "for name, path in files.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}\")\n",
    "        if name == 'vocab':\n",
    "            print(\"ğŸ’¡ è¯æ±‡è¡¨æ–‡ä»¶ä¸æ˜¯å¿…éœ€çš„ï¼Œå¯ä»¥ç»§ç»­ï¼Œä½†å»ºè®®æ£€æŸ¥æ•°æ®å®Œæ•´æ€§\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"å¿…éœ€çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {path}\")\n",
    "\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ab1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–æ•°æ®\n",
    "def read_news_file(file_path):\n",
    "    \"\"\"è¯»å–æ–°é—»æ–‡ä»¶ï¼Œè¿”å›(texts, labels)\"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                # åˆ†å‰²ç±»åˆ«å’Œå†…å®¹(ä½¿ç”¨åˆ¶è¡¨ç¬¦åˆ†å‰²)\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    label = parts[0].strip()\n",
    "                    content = parts[1].strip()\n",
    "                    # åªä¿ç•™è¶³å¤Ÿé•¿åº¦çš„æ–‡æœ¬\n",
    "                    if len(content) > 10:\n",
    "                        texts.append(content)\n",
    "                        labels.append(label)\n",
    "        \n",
    "        print(f\"âœ… ä» {file_path} è¯»å–äº† {len(texts)} æ¡æ–°é—»\")\n",
    "        return texts, labels\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}\")\n",
    "        return [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79c247ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä» data/THUCNews/cnews.train.txt è¯»å–äº† 49999 æ¡æ–°é—»\n",
      "âœ… ä» data/THUCNews/cnews.val.txt è¯»å–äº† 5000 æ¡æ–°é—»\n",
      "âœ… ä» data/THUCNews/cnews.test.txt è¯»å–äº† 10000 æ¡æ–°é—»\n",
      "\n",
      "ğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n",
      "æ€»æ ·æœ¬æ•°: 64999\n",
      "è®­ç»ƒé›†: 49999, éªŒè¯é›†: 5000, æµ‹è¯•é›†: 10000\n",
      "\n",
      "ç±»åˆ«åˆ†å¸ƒ:\n",
      "  ä½“è‚²: 6500 ä¸ªæ ·æœ¬\n",
      "  å¨±ä¹: 6500 ä¸ªæ ·æœ¬\n",
      "  å®¶å±…: 6500 ä¸ªæ ·æœ¬\n",
      "  æˆ¿äº§: 6499 ä¸ªæ ·æœ¬\n",
      "  æ•™è‚²: 6500 ä¸ªæ ·æœ¬\n",
      "  æ—¶å°š: 6500 ä¸ªæ ·æœ¬\n",
      "  æ—¶æ”¿: 6500 ä¸ªæ ·æœ¬\n",
      "  æ¸¸æˆ: 6500 ä¸ªæ ·æœ¬\n",
      "  ç§‘æŠ€: 6500 ä¸ªæ ·æœ¬\n",
      "  è´¢ç»: 6500 ä¸ªæ ·æœ¬\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–è®­ç»ƒé›†\n",
    "train_texts, train_labels = read_news_file(files['train'])\n",
    "\n",
    "# è¯»å–éªŒè¯é›†\n",
    "val_texts, val_labels = read_news_file(files['val'])\n",
    "\n",
    "# è¯»å–æµ‹è¯•é›†\n",
    "test_texts, test_labels = read_news_file(files['test'])\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰æ•°æ®ç”¨äºå°æ ·æœ¬è®­ç»ƒ\n",
    "all_texts = train_texts + val_texts + test_texts\n",
    "all_labels = train_labels + val_labels + test_labels\n",
    "\n",
    "print(f\"\\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\")\n",
    "print(f\"æ€»æ ·æœ¬æ•°: {len(all_texts)}\")\n",
    "print(f\"è®­ç»ƒé›†: {len(train_texts)}, éªŒè¯é›†: {len(val_texts)}, æµ‹è¯•é›†: {len(test_texts)}\")\n",
    "\n",
    "label_counter = Counter(all_labels)\n",
    "print(\"\\nç±»åˆ«åˆ†å¸ƒ:\")\n",
    "for category, count in sorted(label_counter.items()):\n",
    "    print(f\"  {category}: {count} ä¸ªæ ·æœ¬\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f060956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰€æœ‰ç±»åˆ« (10ç±»):\n",
      "['ä½“è‚²', 'å¨±ä¹', 'å®¶å±…', 'æˆ¿äº§', 'æ•™è‚²', 'æ—¶å°š', 'æ—¶æ”¿', 'æ¸¸æˆ', 'ç§‘æŠ€', 'è´¢ç»']\n"
     ]
    }
   ],
   "source": [
    "categories = sorted(set(all_labels))\n",
    "print(f\"æ‰€æœ‰ç±»åˆ« ({len(categories)}ç±»):\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09aa0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š è¯æ±‡è¡¨ä¿¡æ¯:\n",
      "è¯æ±‡è¡¨å¤§å°: 4997 ä¸ªè¯\n",
      "å‰10ä¸ªè¯æ±‡: ['<PAD>', 'ï¼Œ', 'çš„', 'ã€‚', 'ä¸€', 'æ˜¯', 'åœ¨', '0', 'æœ‰', 'ä¸']\n",
      "ç‰¹æ®Šæ ‡è®°: <PAD> (é€šå¸¸è¡¨ç¤ºå¡«å……)\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½è¯æ±‡è¡¨\n",
    "vocab = None\n",
    "try:\n",
    "    with open(files['vocab'], 'r', encoding='utf-8') as f:\n",
    "        vocab = [line.strip() for line in f if line.strip()]\n",
    "        print(f\"\\nğŸ“š è¯æ±‡è¡¨ä¿¡æ¯:\")\n",
    "        print(f\"è¯æ±‡è¡¨å¤§å°: {len(vocab)} ä¸ªè¯\")\n",
    "        print(f\"å‰10ä¸ªè¯æ±‡: {vocab[:10]}\")\n",
    "        print(f\"ç‰¹æ®Šæ ‡è®°: {vocab[0]} (é€šå¸¸è¡¨ç¤ºå¡«å……)\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  åŠ è½½è¯æ±‡è¡¨æ—¶å‡ºé”™: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdf3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä»æ–‡ä»¶åŠ è½½äº† 849 ä¸ªåœç”¨è¯\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'--',\n",
       " '<PAD>',\n",
       " '?',\n",
       " 'â€œ',\n",
       " 'â€',\n",
       " 'ã€‹',\n",
       " 'ä¸€',\n",
       " 'ä¸€ä¸‹',\n",
       " 'ä¸€äº›',\n",
       " 'ä¸€åˆ‡',\n",
       " 'ä¸€åˆ™',\n",
       " 'ä¸€å¤©',\n",
       " 'ä¸€å®š',\n",
       " 'ä¸€æ–¹é¢',\n",
       " 'ä¸€æ—¦',\n",
       " 'ä¸€æ—¶',\n",
       " 'ä¸€æ¥',\n",
       " 'ä¸€æ ·',\n",
       " 'ä¸€æ¬¡',\n",
       " 'ä¸€ç‰‡',\n",
       " 'ä¸€ç›´',\n",
       " 'ä¸€è‡´',\n",
       " 'ä¸€èˆ¬',\n",
       " 'ä¸€èµ·',\n",
       " 'ä¸€è¾¹',\n",
       " 'ä¸€é¢',\n",
       " 'ä¸‡ä¸€',\n",
       " 'ä¸Šä¸‹',\n",
       " 'ä¸Šå‡',\n",
       " 'ä¸Šå»',\n",
       " 'ä¸Šæ¥',\n",
       " 'ä¸Šè¿°',\n",
       " 'ä¸Šé¢',\n",
       " 'ä¸‹åˆ—',\n",
       " 'ä¸‹å»',\n",
       " 'ä¸‹æ¥',\n",
       " 'ä¸‹é¢',\n",
       " 'ä¸ä¸€',\n",
       " 'ä¸ä¹…',\n",
       " 'ä¸ä»…',\n",
       " 'ä¸ä¼š',\n",
       " 'ä¸ä½†',\n",
       " 'ä¸å…‰',\n",
       " 'ä¸å•',\n",
       " 'ä¸å˜',\n",
       " 'ä¸åª',\n",
       " 'ä¸å¯',\n",
       " 'ä¸åŒ',\n",
       " 'ä¸å¤Ÿ',\n",
       " 'ä¸å¦‚',\n",
       " 'ä¸å¾—',\n",
       " 'ä¸æ€•',\n",
       " 'ä¸æƒŸ',\n",
       " 'ä¸æˆ',\n",
       " 'ä¸æ‹˜',\n",
       " 'ä¸æ•¢',\n",
       " 'ä¸æ–­',\n",
       " 'ä¸æ˜¯',\n",
       " 'ä¸æ¯”',\n",
       " 'ä¸ç„¶',\n",
       " 'ä¸ç‰¹',\n",
       " 'ä¸ç‹¬',\n",
       " 'ä¸ç®¡',\n",
       " 'ä¸èƒ½',\n",
       " 'ä¸è¦',\n",
       " 'ä¸è®º',\n",
       " 'ä¸è¶³',\n",
       " 'ä¸è¿‡',\n",
       " 'ä¸é—®',\n",
       " 'ä¸',\n",
       " 'ä¸å…¶',\n",
       " 'ä¸å¦',\n",
       " 'ä¸æ­¤åŒæ—¶',\n",
       " 'ä¸“é—¨',\n",
       " 'ä¸”',\n",
       " 'ä¸¤è€…',\n",
       " 'ä¸¥æ ¼',\n",
       " 'ä¸¥é‡',\n",
       " 'ä¸ª',\n",
       " 'ä¸ªäºº',\n",
       " 'ä¸ªåˆ«',\n",
       " 'ä¸­å°',\n",
       " 'ä¸­é—´',\n",
       " 'ä¸°å¯Œ',\n",
       " 'ä¸´',\n",
       " 'ä¸º',\n",
       " 'ä¸ºä¸»',\n",
       " 'ä¸ºäº†',\n",
       " 'ä¸ºä»€ä¹ˆ',\n",
       " 'ä¸ºä»€éº½',\n",
       " 'ä¸ºä½•',\n",
       " 'ä¸ºç€',\n",
       " 'ä¸»å¼ ',\n",
       " 'ä¸»è¦',\n",
       " 'ä¸¾è¡Œ',\n",
       " 'ä¹ƒ',\n",
       " 'ä¹ƒè‡³',\n",
       " 'ä¹ˆ',\n",
       " 'ä¹‹',\n",
       " 'ä¹‹ä¸€',\n",
       " 'ä¹‹å‰',\n",
       " 'ä¹‹å',\n",
       " 'ä¹‹å¾Œ',\n",
       " 'ä¹‹æ‰€ä»¥',\n",
       " 'ä¹‹ç±»',\n",
       " 'ä¹Œä¹',\n",
       " 'ä¹',\n",
       " 'ä¹˜',\n",
       " 'ä¹Ÿ',\n",
       " 'ä¹Ÿå¥½',\n",
       " 'ä¹Ÿæ˜¯',\n",
       " 'ä¹Ÿç½¢',\n",
       " 'äº†',\n",
       " 'äº†è§£',\n",
       " 'äº‰å–',\n",
       " 'äº',\n",
       " 'äºæ˜¯',\n",
       " 'äºæ˜¯ä¹',\n",
       " 'äº‘äº‘',\n",
       " 'äº’ç›¸',\n",
       " 'äº§ç”Ÿ',\n",
       " 'äººä»¬',\n",
       " 'äººå®¶',\n",
       " 'ä»€ä¹ˆ',\n",
       " 'ä»€ä¹ˆæ ·',\n",
       " 'ä»€éº½',\n",
       " 'ä»Šå',\n",
       " 'ä»Šå¤©',\n",
       " 'ä»Šå¹´',\n",
       " 'ä»Šå¾Œ',\n",
       " 'ä»ç„¶',\n",
       " 'ä»',\n",
       " 'ä»äº‹',\n",
       " 'ä»è€Œ',\n",
       " 'ä»–',\n",
       " 'ä»–äºº',\n",
       " 'ä»–ä»¬',\n",
       " 'ä»–çš„',\n",
       " 'ä»£æ›¿',\n",
       " 'ä»¥',\n",
       " 'ä»¥ä¸Š',\n",
       " 'ä»¥ä¸‹',\n",
       " 'ä»¥ä¸º',\n",
       " 'ä»¥ä¾¿',\n",
       " 'ä»¥å…',\n",
       " 'ä»¥å‰',\n",
       " 'ä»¥åŠ',\n",
       " 'ä»¥å',\n",
       " 'ä»¥å¤–',\n",
       " 'ä»¥å¾Œ',\n",
       " 'ä»¥æ¥',\n",
       " 'ä»¥è‡³',\n",
       " 'ä»¥è‡³äº',\n",
       " 'ä»¥è‡´',\n",
       " 'ä»¬',\n",
       " 'ä»»',\n",
       " 'ä»»ä½•',\n",
       " 'ä»»å‡­',\n",
       " 'ä»»åŠ¡',\n",
       " 'ä¼å›¾',\n",
       " 'ä¼Ÿå¤§',\n",
       " 'ä¼¼ä¹',\n",
       " 'ä¼¼çš„',\n",
       " 'ä½†',\n",
       " 'ä½†æ˜¯',\n",
       " 'ä½•',\n",
       " 'ä½•å†µ',\n",
       " 'ä½•å¤„',\n",
       " 'ä½•æ—¶',\n",
       " 'ä½œä¸º',\n",
       " 'ä½ ',\n",
       " 'ä½ ä»¬',\n",
       " 'ä½ çš„',\n",
       " 'ä½¿å¾—',\n",
       " 'ä½¿ç”¨',\n",
       " 'ä¾‹å¦‚',\n",
       " 'ä¾',\n",
       " 'ä¾ç…§',\n",
       " 'ä¾é ',\n",
       " 'ä¿ƒè¿›',\n",
       " 'ä¿æŒ',\n",
       " 'ä¿º',\n",
       " 'ä¿ºä»¬',\n",
       " 'å€˜',\n",
       " 'å€˜ä½¿',\n",
       " 'å€˜æˆ–',\n",
       " 'å€˜ç„¶',\n",
       " 'å€˜è‹¥',\n",
       " 'å‡ä½¿',\n",
       " 'å‡å¦‚',\n",
       " 'å‡è‹¥',\n",
       " 'åšåˆ°',\n",
       " 'åƒ',\n",
       " 'å…è®¸',\n",
       " 'å……åˆ†',\n",
       " 'å…ˆå',\n",
       " 'å…ˆå¾Œ',\n",
       " 'å…ˆç”Ÿ',\n",
       " 'å…¨éƒ¨',\n",
       " 'å…¨é¢',\n",
       " 'å…®',\n",
       " 'å…±åŒ',\n",
       " 'å…³äº',\n",
       " 'å…¶',\n",
       " 'å…¶ä¸€',\n",
       " 'å…¶ä¸­',\n",
       " 'å…¶äºŒ',\n",
       " 'å…¶ä»–',\n",
       " 'å…¶ä½™',\n",
       " 'å…¶å®ƒ',\n",
       " 'å…¶å®',\n",
       " 'å…¶æ¬¡',\n",
       " 'å…·ä½“',\n",
       " 'å…·ä½“åœ°è¯´',\n",
       " 'å…·ä½“è¯´æ¥',\n",
       " 'å…·æœ‰',\n",
       " 'å†è€…',\n",
       " 'å†è¯´',\n",
       " 'å†’',\n",
       " 'å†²',\n",
       " 'å†³å®š',\n",
       " 'å†µä¸”',\n",
       " 'å‡†å¤‡',\n",
       " 'å‡ ',\n",
       " 'å‡ ä¹',\n",
       " 'å‡ æ—¶',\n",
       " 'å‡­',\n",
       " 'å‡­å€Ÿ',\n",
       " 'å‡ºå»',\n",
       " 'å‡ºæ¥',\n",
       " 'å‡ºç°',\n",
       " 'åˆ†åˆ«',\n",
       " 'åˆ™',\n",
       " 'åˆ«',\n",
       " 'åˆ«çš„',\n",
       " 'åˆ«è¯´',\n",
       " 'åˆ°',\n",
       " 'å‰å',\n",
       " 'å‰è€…',\n",
       " 'å‰è¿›',\n",
       " 'å‰é¢',\n",
       " 'åŠ ä¹‹',\n",
       " 'åŠ ä»¥',\n",
       " 'åŠ å…¥',\n",
       " 'åŠ å¼º',\n",
       " 'ååˆ†',\n",
       " 'å³',\n",
       " 'å³ä»¤',\n",
       " 'å³ä½¿',\n",
       " 'å³ä¾¿',\n",
       " 'å³æˆ–',\n",
       " 'å³è‹¥',\n",
       " 'å´ä¸',\n",
       " 'åŸæ¥',\n",
       " 'åˆ',\n",
       " 'åŠ',\n",
       " 'åŠå…¶',\n",
       " 'åŠæ—¶',\n",
       " 'åŠè‡³',\n",
       " 'åŒæ–¹',\n",
       " 'åä¹‹',\n",
       " 'ååº”',\n",
       " 'åæ˜ ',\n",
       " 'åè¿‡æ¥',\n",
       " 'åè¿‡æ¥è¯´',\n",
       " 'å–å¾—',\n",
       " 'å—åˆ°',\n",
       " 'å˜æˆ',\n",
       " 'å¦',\n",
       " 'å¦ä¸€æ–¹é¢',\n",
       " 'å¦å¤–',\n",
       " 'åªæ˜¯',\n",
       " 'åªæœ‰',\n",
       " 'åªè¦',\n",
       " 'åªé™',\n",
       " 'å«',\n",
       " 'å«åš',\n",
       " 'å¬å¼€',\n",
       " 'å®å’š',\n",
       " 'å¯',\n",
       " 'å¯ä»¥',\n",
       " 'å¯æ˜¯',\n",
       " 'å¯èƒ½',\n",
       " 'å¯è§',\n",
       " 'å„',\n",
       " 'å„ä¸ª',\n",
       " 'å„äºº',\n",
       " 'å„ä½',\n",
       " 'å„åœ°',\n",
       " 'å„ç§',\n",
       " 'å„çº§',\n",
       " 'å„è‡ª',\n",
       " 'åˆç†',\n",
       " 'åŒ',\n",
       " 'åŒä¸€',\n",
       " 'åŒæ—¶',\n",
       " 'åŒæ ·',\n",
       " 'åæ¥',\n",
       " 'åé¢',\n",
       " 'å‘',\n",
       " 'å‘ç€',\n",
       " 'å“',\n",
       " 'å—',\n",
       " 'å¦åˆ™',\n",
       " 'å§',\n",
       " 'å§å“’',\n",
       " 'å±',\n",
       " 'å‘€',\n",
       " 'å‘ƒ',\n",
       " 'å‘•',\n",
       " 'å‘—',\n",
       " 'å‘œ',\n",
       " 'å‘œå‘¼',\n",
       " 'å‘¢',\n",
       " 'å‘¨å›´',\n",
       " 'å‘µ',\n",
       " 'å‘¸',\n",
       " 'å‘¼å“§',\n",
       " 'å’‹',\n",
       " 'å’Œ',\n",
       " 'å’š',\n",
       " 'å’¦',\n",
       " 'å’±',\n",
       " 'å’±ä»¬',\n",
       " 'å’³',\n",
       " 'å“‡',\n",
       " 'å“ˆ',\n",
       " 'å“ˆå“ˆ',\n",
       " 'å“‰',\n",
       " 'å“',\n",
       " 'å“å‘€',\n",
       " 'å“å“Ÿ',\n",
       " 'å“—',\n",
       " 'å“Ÿ',\n",
       " 'å“¦',\n",
       " 'å“©',\n",
       " 'å“ª',\n",
       " 'å“ªä¸ª',\n",
       " 'å“ªäº›',\n",
       " 'å“ªå„¿',\n",
       " 'å“ªå¤©',\n",
       " 'å“ªå¹´',\n",
       " 'å“ªæ€•',\n",
       " 'å“ªæ ·',\n",
       " 'å“ªè¾¹',\n",
       " 'å“ªé‡Œ',\n",
       " 'å“¼',\n",
       " 'å“¼å”·',\n",
       " 'å”‰',\n",
       " 'å•Š',\n",
       " 'å•',\n",
       " 'å•¥',\n",
       " 'å•¦',\n",
       " 'å•ªè¾¾',\n",
       " 'å–‚',\n",
       " 'å–',\n",
       " 'å–”å”·',\n",
       " 'å—¡å—¡',\n",
       " 'å—¬',\n",
       " 'å—¯',\n",
       " 'å—³',\n",
       " 'å˜',\n",
       " 'å˜ç™»',\n",
       " 'å˜˜',\n",
       " 'å˜›',\n",
       " 'å˜»',\n",
       " 'å˜¿',\n",
       " 'å› ',\n",
       " 'å› ä¸º',\n",
       " 'å› æ­¤',\n",
       " 'å› è€Œ',\n",
       " 'å›ºç„¶',\n",
       " 'åœ¨',\n",
       " 'åœ¨ä¸‹',\n",
       " 'åœ°',\n",
       " 'åšå†³',\n",
       " 'åšæŒ',\n",
       " 'åŸºæœ¬',\n",
       " 'å¤„ç†',\n",
       " 'å¤æ‚',\n",
       " 'å¤š',\n",
       " 'å¤šå°‘',\n",
       " 'å¤šæ•°',\n",
       " 'å¤šæ¬¡',\n",
       " 'å¤§åŠ›',\n",
       " 'å¤§å¤šæ•°',\n",
       " 'å¤§å¤§',\n",
       " 'å¤§å®¶',\n",
       " 'å¤§æ‰¹',\n",
       " 'å¤§çº¦',\n",
       " 'å¤§é‡',\n",
       " 'å¤±å»',\n",
       " 'å¥¹',\n",
       " 'å¥¹ä»¬',\n",
       " 'å¥¹çš„',\n",
       " 'å¥½çš„',\n",
       " 'å¥½è±¡',\n",
       " 'å¦‚',\n",
       " 'å¦‚ä¸Šæ‰€è¿°',\n",
       " 'å¦‚ä¸‹',\n",
       " 'å¦‚ä½•',\n",
       " 'å¦‚å…¶',\n",
       " 'å¦‚æœ',\n",
       " 'å¦‚æ­¤',\n",
       " 'å¦‚è‹¥',\n",
       " 'å­˜åœ¨',\n",
       " 'å®',\n",
       " 'å®å¯',\n",
       " 'å®æ„¿',\n",
       " 'å®è‚¯',\n",
       " 'å®ƒ',\n",
       " 'å®ƒä»¬',\n",
       " 'å®ƒä»¬çš„',\n",
       " 'å®ƒçš„',\n",
       " 'å®‰å…¨',\n",
       " 'å®Œå…¨',\n",
       " 'å®Œæˆ',\n",
       " 'å®ç°',\n",
       " 'å®é™…',\n",
       " 'å®£å¸ƒ',\n",
       " 'å®¹æ˜“',\n",
       " 'å¯†åˆ‡',\n",
       " 'å¯¹',\n",
       " 'å¯¹äº',\n",
       " 'å¯¹åº”',\n",
       " 'å°†',\n",
       " 'å°‘æ•°',\n",
       " 'å°”å',\n",
       " 'å°šä¸”',\n",
       " 'å°¤å…¶',\n",
       " 'å°±',\n",
       " 'å°±æ˜¯',\n",
       " 'å°±æ˜¯è¯´',\n",
       " 'å°½',\n",
       " 'å°½ç®¡',\n",
       " 'å±äº',\n",
       " 'å²‚ä½†',\n",
       " 'å·¦å³',\n",
       " 'å·¨å¤§',\n",
       " 'å·©å›º',\n",
       " 'å·±',\n",
       " 'å·²ç»',\n",
       " 'å¸®åŠ©',\n",
       " 'å¸¸å¸¸',\n",
       " 'å¹¶',\n",
       " 'å¹¶ä¸',\n",
       " 'å¹¶ä¸æ˜¯',\n",
       " 'å¹¶ä¸”',\n",
       " 'å¹¶æ²¡æœ‰',\n",
       " 'å¹¿å¤§',\n",
       " 'å¹¿æ³›',\n",
       " 'åº”å½“',\n",
       " 'åº”ç”¨',\n",
       " 'åº”è¯¥',\n",
       " 'å¼€å¤–',\n",
       " 'å¼€å§‹',\n",
       " 'å¼€å±•',\n",
       " 'å¼•èµ·',\n",
       " 'å¼ºçƒˆ',\n",
       " 'å¼ºè°ƒ',\n",
       " 'å½’',\n",
       " 'å½“',\n",
       " 'å½“å‰',\n",
       " 'å½“æ—¶',\n",
       " 'å½“ç„¶',\n",
       " 'å½“ç€',\n",
       " 'å½¢æˆ',\n",
       " 'å½»åº•',\n",
       " 'å½¼',\n",
       " 'å½¼æ­¤',\n",
       " 'å¾€',\n",
       " 'å¾€å¾€',\n",
       " 'å¾…',\n",
       " 'å¾Œæ¥',\n",
       " 'å¾Œé¢',\n",
       " 'å¾—',\n",
       " 'å¾—å‡º',\n",
       " 'å¾—åˆ°',\n",
       " 'å¿ƒé‡Œ',\n",
       " 'å¿…ç„¶',\n",
       " 'å¿…è¦',\n",
       " 'å¿…é¡»',\n",
       " 'æ€',\n",
       " 'æ€ä¹ˆ',\n",
       " 'æ€ä¹ˆåŠ',\n",
       " 'æ€ä¹ˆæ ·',\n",
       " 'æ€æ ·',\n",
       " 'æ€éº½',\n",
       " 'æ€»ä¹‹',\n",
       " 'æ€»æ˜¯',\n",
       " 'æ€»çš„æ¥çœ‹',\n",
       " 'æ€»çš„æ¥è¯´',\n",
       " 'æ€»çš„è¯´æ¥',\n",
       " 'æ€»ç»“',\n",
       " 'æ€»è€Œè¨€ä¹‹',\n",
       " 'æ°æ°ç›¸å',\n",
       " 'æ‚¨',\n",
       " 'æ„æ€',\n",
       " 'æ„¿æ„',\n",
       " 'æ…¢è¯´',\n",
       " 'æˆä¸º',\n",
       " 'æˆ‘',\n",
       " 'æˆ‘ä»¬',\n",
       " 'æˆ‘çš„',\n",
       " 'æˆ–',\n",
       " 'æˆ–æ˜¯',\n",
       " 'æˆ–è€…',\n",
       " 'æˆ˜æ–—',\n",
       " 'æ‰€',\n",
       " 'æ‰€ä»¥',\n",
       " 'æ‰€æœ‰',\n",
       " 'æ‰€è°“',\n",
       " 'æ‰“',\n",
       " 'æ‰©å¤§',\n",
       " 'æŠŠ',\n",
       " 'æŠ‘æˆ–',\n",
       " 'æ‹¿',\n",
       " 'æŒ‰',\n",
       " 'æŒ‰ç…§',\n",
       " 'æ¢å¥è¯è¯´',\n",
       " 'æ¢è¨€ä¹‹',\n",
       " 'æ®',\n",
       " 'æŒæ¡',\n",
       " 'æ¥ç€',\n",
       " 'æ¥è‘—',\n",
       " 'æ•…',\n",
       " 'æ•…æ­¤',\n",
       " 'æ•´ä¸ª',\n",
       " 'æ–¹ä¾¿',\n",
       " 'æ–¹é¢',\n",
       " 'æ—äºº',\n",
       " 'æ— å®',\n",
       " 'æ— æ³•',\n",
       " 'æ— è®º',\n",
       " 'æ—¢',\n",
       " 'æ—¢æ˜¯',\n",
       " 'æ—¢ç„¶',\n",
       " 'æ—¶å€™',\n",
       " 'æ˜æ˜¾',\n",
       " 'æ˜ç¡®',\n",
       " 'æ˜¯',\n",
       " 'æ˜¯ä¸æ˜¯',\n",
       " 'æ˜¯å¦',\n",
       " 'æ˜¯çš„',\n",
       " 'æ˜¾ç„¶',\n",
       " 'æ˜¾è‘—',\n",
       " 'æ™®é€š',\n",
       " 'æ™®é',\n",
       " 'æ›´åŠ ',\n",
       " 'æ›¾ç»',\n",
       " 'æ›¿',\n",
       " 'æœ€å',\n",
       " 'æœ€å¤§',\n",
       " 'æœ€å¥½',\n",
       " 'æœ€å¾Œ',\n",
       " 'æœ€è¿‘',\n",
       " 'æœ€é«˜',\n",
       " 'æœ‰',\n",
       " 'æœ‰äº›',\n",
       " 'æœ‰å…³',\n",
       " 'æœ‰åˆ©',\n",
       " 'æœ‰åŠ›',\n",
       " 'æœ‰æ‰€',\n",
       " 'æœ‰æ•ˆ',\n",
       " 'æœ‰æ—¶',\n",
       " 'æœ‰ç‚¹',\n",
       " 'æœ‰çš„',\n",
       " 'æœ‰ç€',\n",
       " 'æœ‰è‘—',\n",
       " 'æœ›',\n",
       " 'æœ',\n",
       " 'æœç€',\n",
       " 'æœ¬',\n",
       " 'æœ¬ç€',\n",
       " 'æ¥',\n",
       " 'æ¥ç€',\n",
       " 'æäº†',\n",
       " 'æ„æˆ',\n",
       " 'æœç„¶',\n",
       " 'æœçœŸ',\n",
       " 'æŸ',\n",
       " 'æŸä¸ª',\n",
       " 'æŸäº›',\n",
       " 'æ ¹æ®',\n",
       " 'æ ¹æœ¬',\n",
       " 'æ¬¢è¿',\n",
       " 'æ­£åœ¨',\n",
       " 'æ­£å¦‚',\n",
       " 'æ­£å¸¸',\n",
       " 'æ­¤',\n",
       " 'æ­¤å¤–',\n",
       " 'æ­¤æ—¶',\n",
       " 'æ­¤é—´',\n",
       " 'æ¯‹å®',\n",
       " 'æ¯',\n",
       " 'æ¯ä¸ª',\n",
       " 'æ¯å¤©',\n",
       " 'æ¯å¹´',\n",
       " 'æ¯å½“',\n",
       " 'æ¯”',\n",
       " 'æ¯”å¦‚',\n",
       " 'æ¯”æ–¹',\n",
       " 'æ¯”è¾ƒ',\n",
       " 'æ¯«ä¸',\n",
       " 'æ²¡æœ‰',\n",
       " 'æ²¿',\n",
       " 'æ²¿ç€',\n",
       " 'æ³¨æ„',\n",
       " 'æ·±å…¥',\n",
       " 'æ¸…æ¥š',\n",
       " 'æ»¡è¶³',\n",
       " 'æ¼«è¯´',\n",
       " 'ç„‰',\n",
       " 'ç„¶åˆ™',\n",
       " 'ç„¶å',\n",
       " 'ç„¶å¾Œ',\n",
       " 'ç„¶è€Œ',\n",
       " 'ç…§',\n",
       " 'ç…§ç€',\n",
       " 'ç‰¹åˆ«æ˜¯',\n",
       " 'ç‰¹æ®Š',\n",
       " 'ç‰¹ç‚¹',\n",
       " 'ç°ä»£',\n",
       " 'ç°åœ¨',\n",
       " 'ç”šä¹ˆ',\n",
       " 'ç”šè€Œ',\n",
       " 'ç”šè‡³',\n",
       " 'ç”¨',\n",
       " 'ç”±',\n",
       " 'ç”±äº',\n",
       " 'ç”±æ­¤å¯è§',\n",
       " 'çš„',\n",
       " 'çš„è¯',\n",
       " 'ç›®å‰',\n",
       " 'ç›´åˆ°',\n",
       " 'ç›´æ¥',\n",
       " 'ç›¸ä¼¼',\n",
       " 'ç›¸ä¿¡',\n",
       " 'ç›¸å',\n",
       " 'ç›¸åŒ',\n",
       " 'ç›¸å¯¹',\n",
       " 'ç›¸å¯¹è€Œè¨€',\n",
       " 'ç›¸åº”',\n",
       " 'ç›¸å½“',\n",
       " 'ç›¸ç­‰',\n",
       " 'çœå¾—',\n",
       " 'çœ‹å‡º',\n",
       " 'çœ‹åˆ°',\n",
       " 'çœ‹æ¥',\n",
       " 'çœ‹çœ‹',\n",
       " 'çœ‹è§',\n",
       " 'çœŸæ˜¯',\n",
       " 'çœŸæ­£',\n",
       " 'ç€',\n",
       " 'ç€å‘¢',\n",
       " 'çŸ£',\n",
       " 'çŸ¥é“',\n",
       " 'ç¡®å®š',\n",
       " 'ç¦»',\n",
       " 'ç§¯æ',\n",
       " 'ç§»åŠ¨',\n",
       " 'çªå‡º',\n",
       " 'çªç„¶',\n",
       " 'ç«‹å³',\n",
       " 'ç¬¬',\n",
       " 'ç­‰',\n",
       " 'ç­‰ç­‰',\n",
       " 'ç®¡',\n",
       " 'ç´§æ¥ç€',\n",
       " 'çºµ',\n",
       " 'çºµä»¤',\n",
       " 'çºµä½¿',\n",
       " 'çºµç„¶',\n",
       " 'ç»ƒä¹ ',\n",
       " 'ç»„æˆ',\n",
       " 'ç»',\n",
       " 'ç»å¸¸',\n",
       " 'ç»è¿‡',\n",
       " 'ç»“åˆ',\n",
       " 'ç»“æœ',\n",
       " 'ç»™',\n",
       " 'ç»å¯¹',\n",
       " 'ç»§ç»­',\n",
       " 'ç»§è€Œ',\n",
       " 'ç»´æŒ',\n",
       " 'ç»¼ä¸Šæ‰€è¿°',\n",
       " 'ç½¢äº†',\n",
       " 'è€ƒè™‘',\n",
       " 'è€…',\n",
       " 'è€Œ',\n",
       " 'è€Œä¸”',\n",
       " 'è€Œå†µ',\n",
       " 'è€Œå¤–',\n",
       " 'è€Œå·²',\n",
       " 'è€Œæ˜¯',\n",
       " 'è€Œè¨€',\n",
       " 'è”ç³»',\n",
       " 'èƒ½',\n",
       " 'èƒ½å¦',\n",
       " 'èƒ½å¤Ÿ',\n",
       " 'è…¾',\n",
       " 'è‡ª',\n",
       " 'è‡ªä¸ªå„¿',\n",
       " 'è‡ªä»',\n",
       " 'è‡ªå„å„¿',\n",
       " 'è‡ªå®¶',\n",
       " 'è‡ªå·±',\n",
       " 'è‡ªèº«',\n",
       " 'è‡³',\n",
       " 'è‡³äº',\n",
       " 'è‰¯å¥½',\n",
       " 'è‹¥',\n",
       " 'è‹¥æ˜¯',\n",
       " 'è‹¥é',\n",
       " 'èŒƒå›´',\n",
       " 'è«è‹¥',\n",
       " 'è·å¾—',\n",
       " 'è™½',\n",
       " 'è™½åˆ™',\n",
       " 'è™½ç„¶',\n",
       " 'è™½è¯´',\n",
       " 'è¡Œä¸º',\n",
       " 'è¡ŒåŠ¨',\n",
       " 'è¡¨æ˜',\n",
       " 'è¡¨ç¤º',\n",
       " 'è¢«',\n",
       " 'è¦',\n",
       " 'è¦ä¸',\n",
       " 'è¦ä¸æ˜¯',\n",
       " 'è¦ä¸ç„¶',\n",
       " 'è¦ä¹ˆ',\n",
       " 'è¦æ˜¯',\n",
       " 'è¦æ±‚',\n",
       " 'è§„å®š',\n",
       " 'è§‰å¾—',\n",
       " 'è®¤ä¸º',\n",
       " 'è®¤çœŸ',\n",
       " 'è®¤è¯†',\n",
       " 'è®©',\n",
       " 'è®¸å¤š',\n",
       " 'è®º',\n",
       " 'è®¾ä½¿',\n",
       " 'è®¾è‹¥',\n",
       " 'è¯¥',\n",
       " 'è¯´æ˜',\n",
       " 'è¯´è¯´',\n",
       " 'è¯¸ä½',\n",
       " 'è°',\n",
       " 'è°çŸ¥',\n",
       " 'èµ¶',\n",
       " 'èµ·',\n",
       " 'èµ·æ¥',\n",
       " 'èµ·è§',\n",
       " 'è¶',\n",
       " 'è¶ç€',\n",
       " 'è¶Šæ˜¯',\n",
       " 'è·Ÿ',\n",
       " 'è½¬åŠ¨',\n",
       " 'è½¬å˜',\n",
       " 'è½¬è´´',\n",
       " 'è¾ƒ',\n",
       " 'è¾ƒä¹‹',\n",
       " 'è¾¹',\n",
       " 'è¾¾åˆ°',\n",
       " 'è¿…é€Ÿ',\n",
       " 'è¿‡',\n",
       " 'è¿‡å»',\n",
       " 'è¿‡æ¥',\n",
       " 'è¿ç”¨',\n",
       " 'è¿˜æ˜¯',\n",
       " 'è¿˜æœ‰',\n",
       " 'è¿™',\n",
       " 'è¿™ä¸ª',\n",
       " 'è¿™ä¹ˆ',\n",
       " 'è¿™ä¹ˆäº›',\n",
       " 'è¿™ä¹ˆæ ·',\n",
       " 'è¿™ä¹ˆç‚¹å„¿',\n",
       " 'è¿™äº›',\n",
       " 'è¿™ä¼šå„¿',\n",
       " 'è¿™å„¿',\n",
       " 'è¿™å°±æ˜¯è¯´',\n",
       " 'è¿™æ—¶',\n",
       " 'è¿™æ ·',\n",
       " 'è¿™ç‚¹',\n",
       " 'è¿™ç§',\n",
       " 'è¿™è¾¹',\n",
       " 'è¿™é‡Œ',\n",
       " 'è¿™éº½',\n",
       " 'è¿›å…¥',\n",
       " 'è¿›æ­¥',\n",
       " 'è¿›è€Œ',\n",
       " 'è¿›è¡Œ',\n",
       " 'è¿',\n",
       " 'è¿åŒ',\n",
       " 'é€‚åº”',\n",
       " 'é€‚å½“',\n",
       " 'é€‚ç”¨',\n",
       " 'é€æ­¥',\n",
       " 'é€æ¸',\n",
       " 'é€šå¸¸',\n",
       " 'é€šè¿‡',\n",
       " 'é€ æˆ',\n",
       " 'é‡åˆ°',\n",
       " 'é­åˆ°',\n",
       " 'é¿å…',\n",
       " 'é‚£',\n",
       " 'é‚£ä¸ª',\n",
       " 'é‚£ä¹ˆ',\n",
       " 'é‚£ä¹ˆäº›',\n",
       " 'é‚£ä¹ˆæ ·',\n",
       " 'é‚£äº›',\n",
       " 'é‚£ä¼šå„¿',\n",
       " 'é‚£å„¿',\n",
       " 'é‚£æ—¶',\n",
       " 'é‚£æ ·',\n",
       " 'é‚£è¾¹',\n",
       " 'é‚£é‡Œ',\n",
       " 'é‚£éº½',\n",
       " 'éƒ¨åˆ†',\n",
       " 'é„™äºº',\n",
       " 'é‡‡å–',\n",
       " 'é‡Œé¢',\n",
       " 'é‡å¤§',\n",
       " 'é‡æ–°',\n",
       " 'é‡è¦',\n",
       " 'é‰´äº',\n",
       " 'é—®é¢˜',\n",
       " 'é˜²æ­¢',\n",
       " 'é˜¿',\n",
       " 'é™„è¿‘',\n",
       " 'é™åˆ¶',\n",
       " 'é™¤',\n",
       " 'é™¤äº†',\n",
       " 'é™¤æ­¤ä¹‹å¤–',\n",
       " 'é™¤é',\n",
       " 'éš',\n",
       " 'éšç€',\n",
       " 'éšè‘—',\n",
       " 'é›†ä¸­',\n",
       " 'éœ€è¦',\n",
       " 'éä½†',\n",
       " 'éå¸¸',\n",
       " 'éå¾’',\n",
       " 'é ',\n",
       " 'é¡º',\n",
       " 'é¡ºç€',\n",
       " 'é¦–å…ˆ',\n",
       " 'é«˜å…´',\n",
       " 'ï¼ï¼'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŠ è½½ä¸­æ–‡åœç”¨è¯\n",
    "stopwords_file = \"data/stopwords_cn.txt\"\n",
    "stopwords = []\n",
    "\n",
    "try:\n",
    "    with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
    "        file_stopwords = [line.strip() for line in f if line.strip()]\n",
    "        # é€ä¸ªæ·»åŠ \n",
    "        stopwords.extend(file_stopwords)\n",
    "        # å»é‡\n",
    "        stopwords = set(stopwords)\n",
    "        print(f\"âœ… ä»æ–‡ä»¶åŠ è½½äº† {len(file_stopwords)} ä¸ªåœç”¨è¯\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  åŠ è½½åœç”¨è¯æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "833977ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'é©¬æ™“æ—­ æ„å¤– å—ä¼¤ å›½å¥¥ è­¦æƒ• æ— å¥ˆ å¤§é›¨ æ ¼å¤– é’ç æ®·å®¶ è®°è€… å‚…äºšé›¨ æ²ˆé˜³ æŠ¥é“ æ¥åˆ° æ²ˆé˜³ '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_texts[0]\n",
    "\n",
    "text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)   # ç§»é™¤URL\n",
    "text = re.sub(r'\\S*@\\S*\\s?', '', text)  # ç§»é™¤ç”µå­é‚®ä»¶åœ°å€\n",
    "text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)    # åªä¿ç•™æ±‰å­—\n",
    "text = re.sub(r'\\s+', ' ', text).strip()    # åˆå¹¶ç©ºç™½å­—ç¬¦å¹¶å»é™¤é¦–å°¾ç©ºæ ¼\n",
    "\n",
    "# 2. ä¸­æ–‡åˆ†è¯\n",
    "if True:\n",
    "    words = jieba.lcut(text)\n",
    "\n",
    "# 4. æ–‡æœ¬æ¸…æ´—\n",
    "filtered_words = [\n",
    "    word.strip() for word in words\n",
    "    if word.strip() not in stopwords    # ä¸åœ¨åœç”¨è¯ä¸­\n",
    "    and len(word.strip()) > 1       # éå•å­—è¯\n",
    "    and not word.strip().isdigit()      # ä¸æ˜¯çº¯æ•°å­—\n",
    "]\n",
    "\n",
    "Processed_text = \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "Processed_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0a563a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸­æ–‡é¢„å¤„ç†\n",
    "def preprocess_cn_text(text, use_jieba=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - use_jieba: æ˜¯å¦ä½¿ç”¨jiebaåˆ†è¯\n",
    "    \"\"\"\n",
    "    # 1. ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå™ªå£°\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)   # ç§»é™¤URL\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # ç§»é™¤ç”µå­é‚®ä»¶åœ°å€\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)    # åªä¿ç•™æ±‰å­—\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # åˆå¹¶ç©ºç™½å­—ç¬¦å¹¶å»é™¤é¦–å°¾ç©ºæ ¼\n",
    "\n",
    "    if not text or len(text) < 5:\n",
    "        return \"\"\n",
    "\n",
    "    # 2. ä¸­æ–‡åˆ†è¯\n",
    "    if use_jieba:\n",
    "        words = jieba.lcut(text)\n",
    "    else:\n",
    "        print(\"âš ï¸   ç®€å•æŒ‰å­—ç¬¦åˆ†å‰²ï¼ˆä¸æ¨èï¼Œä»…ç”¨äºè°ƒè¯•ï¼‰\")\n",
    "        words = [char for char in text if char.strip()]\n",
    "\n",
    "    # 3. åŠ è½½ä¸­æ–‡åœç”¨è¯\n",
    "    # stopwords = stopwords\n",
    "    \n",
    "    # 4. æ–‡æœ¬æ¸…æ´—\n",
    "    filtered_words = [\n",
    "        word.strip() for word in words\n",
    "        if word.strip() not in stopwords    # ä¸åœ¨åœç”¨è¯ä¸­\n",
    "        and len(word.strip()) > 1       # éå•å­—è¯\n",
    "        and not word.strip().isdigit()      # ä¸æ˜¯çº¯æ•°å­—\n",
    "    ]\n",
    "\n",
    "    Processed_text = \" \".join(filtered_words)\n",
    "\n",
    "    return Processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹æ¬¡å¤„ç†\n",
    "def batch_preprocess_texts(texts, batch_size=1000):\n",
    "    \"\"\"\n",
    "    æ‰¹é‡é¢„å¤„ç†æ–‡æœ¬ï¼Œæ˜¾ç¤ºè¿›åº¦\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ”„ æ‰¹é‡é¢„å¤„ç†ä¸­æ–‡æ–‡æœ¬...\")\n",
    "    print(f\"æ€»æ ·æœ¬æ•°: {len(texts)}\")\n",
    "    \n",
    "    processed_texts = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_processed = [preprocess_cn_text(text) for text in batch]\n",
    "        processed_texts.extend(batch_processed)\n",
    "        \n",
    "        # æ˜¾ç¤ºè¿›åº¦\n",
    "        progress = min(i + batch_size, len(texts))\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_sample = elapsed_time / (i + batch_size)\n",
    "        remaining_time = avg_time_per_sample * (len(texts) - progress)\n",
    "        \n",
    "        print(f\"  è¿›åº¦: {progress}/{len(texts)} ({progress/len(texts)*100:.1f}%) \"\n",
    "              f\"- é¢„è®¡å‰©ä½™æ—¶é—´: {remaining_time:.1f}ç§’\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"âœ… æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f}ç§’\")\n",
    "\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20760082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç±»åˆ«æ˜ å°„: {0: 'ä½“è‚²', 1: 'å¨±ä¹', 2: 'å®¶å±…', 3: 'æˆ¿äº§', 4: 'æ•™è‚²', 5: 'æ—¶å°š', 6: 'æ—¶æ”¿', 7: 'æ¸¸æˆ', 8: 'ç§‘æŠ€', 9: 'è´¢ç»'}\n",
      "ç±»åˆ«æ•°é‡: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [0],\n",
       " 1: [1],\n",
       " 2: [2],\n",
       " 3: [3],\n",
       " 4: [4],\n",
       " 5: [5],\n",
       " 6: [6],\n",
       " 7: [7],\n",
       " 8: [8],\n",
       " 9: [9]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_size = 1000\n",
    "\n",
    "# # å°†æ ‡ç­¾è½¬ä¸ºæ•°å€¼\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoder = label_encoder.fit_transform(categories)\n",
    "\n",
    "# # åˆ›å»ºç±»åˆ«æ˜ å°„\n",
    "# class_mapping = {i: category for i, category in enumerate(label_encoder.classes_)}\n",
    "# print(f\"ç±»åˆ«æ˜ å°„: {class_mapping}\")\n",
    "# print(f\"ç±»åˆ«æ•°é‡: {len(class_mapping)}\")\n",
    "\n",
    "# # ä¿è¯ç±»åˆ«å¹³è¡¡çš„å°æ ·æœ¬é€‰æ‹©\n",
    "# # æŒ‰ç±»åˆ«åˆ†ç»„\n",
    "# category_indices = {}\n",
    "# for idx, label in enumerate(y_encoder):\n",
    "#     if label not in category_indices:\n",
    "#         category_indices[label] = []\n",
    "#     category_indices[label].append(idx)\n",
    "\n",
    "# # ä¸ºæ¯ä¸ªç±»åˆ«é€‰æ‹©æ ·æœ¬\n",
    "# selected_indices = []\n",
    "# samples_per_category = max(1, 1000 // len(class_mapping))\n",
    "\n",
    "# for category, indices in category_indices.items():\n",
    "#     # éšæœºé€‰æ‹©è¯¥ç±»åˆ«çš„æ ·æœ¬\n",
    "#     category_samples = min(len(indices), samples_per_category)\n",
    "#     selected = np.random.choice(indices, category_samples, replace=False)\n",
    "#     selected_indices.extend(selected)\n",
    "\n",
    "\n",
    "# category_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_thucnews_small_sample(texts, labels, sample_size=1000, \n",
    "#                                  feature_type='tfidf', max_features=2000, \n",
    "#                                  use_pca=False, n_components=150):\n",
    "#     \"\"\"\n",
    "#     å‡†å¤‡THUCNewså°æ ·æœ¬æ•°æ®é›†ï¼ˆé€‚é…æ ‡å‡†æ ¼å¼ï¼‰\n",
    "    \n",
    "#     Parameters:\n",
    "#     - sample_size: å°æ ·æœ¬å¤§å°\n",
    "#     - feature_type: ç‰¹å¾ç±»å‹ ('tfidf', 'count', 'binary')\n",
    "#     - max_features: æœ€å¤§ç‰¹å¾æ•°\n",
    "#     - use_pca: æ˜¯å¦ä½¿ç”¨PCAé™ç»´\n",
    "#     - n_components: PCAé™ç»´åçš„ç»´åº¦\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(f\"ğŸ”§ å‡†å¤‡THUCNewså°æ ·æœ¬æ•°æ®é›† (æ ·æœ¬æ•°: {sample_size})...\")\n",
    "    \n",
    "#     # è½¬æ¢æ ‡ç­¾ä¸ºæ•°å€¼\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     y_encoded = label_encoder.fit_transform(labels)\n",
    "    \n",
    "#     # åˆ›å»ºç±»åˆ«æ˜ å°„\n",
    "#     class_mapping = {i: category for i, category in enumerate(label_encoder.classes_)}\n",
    "#     print(f\"ç±»åˆ«æ˜ å°„: {class_mapping}\")\n",
    "#     print(f\"ç±»åˆ«æ•°é‡: {len(class_mapping)}\")\n",
    "    \n",
    "#     # ä¿è¯ç±»åˆ«å¹³è¡¡çš„å°æ ·æœ¬é€‰æ‹©\n",
    "#     print(\"\\nğŸ”„ é€‰æ‹©ç±»åˆ«å¹³è¡¡çš„å°æ ·æœ¬...\")\n",
    "    \n",
    "#     # æŒ‰ç±»åˆ«åˆ†ç»„\n",
    "#     category_indices = {}\n",
    "#     for idx, label in enumerate(y_encoded):\n",
    "#         if label not in category_indices:\n",
    "#             category_indices[label] = []\n",
    "#         category_indices[label].append(idx)\n",
    "    \n",
    "#     # ä¸ºæ¯ä¸ªç±»åˆ«é€‰æ‹©æ ·æœ¬\n",
    "#     selected_indices = []\n",
    "#     samples_per_category = max(1, sample_size // len(class_mapping))\n",
    "    \n",
    "#     for category, indices in category_indices.items():\n",
    "#         # éšæœºé€‰æ‹©è¯¥ç±»åˆ«çš„æ ·æœ¬\n",
    "#         category_samples = min(len(indices), samples_per_category)\n",
    "#         selected = np.random.choice(indices, category_samples, replace=False)\n",
    "#         selected_indices.extend(selected)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06b342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 4999)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_np = np.array(train_labels)\n",
    "indices_tmp = np.where(train_labels_np == 'æˆ¿äº§')[0].tolist()\n",
    "\n",
    "train_texts_category = train_texts[int(indices_tmp[0]): int(indices_tmp[-1]+1)]\n",
    "len(indices_tmp),len(train_texts_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6575e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thucnews_sample(texts, labels, categories, sample_size=1000,\n",
    "                           feature_type='tfidf', max_features=2000, \n",
    "                           use_pca=False, n_components=150):\n",
    "    \"\"\"\n",
    "    å‡†å¤‡THUCNewså°æ ·æœ¬æ•°æ®é›†ï¼ˆé€‚é…æ ‡å‡†æ ¼å¼ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    - sample_size: å°æ ·æœ¬å¤§å°\n",
    "    - feature_type: ç‰¹å¾ç±»å‹ ('tfidf', 'count', 'binary')\n",
    "    - max_features: æœ€å¤§ç‰¹å¾æ•°\n",
    "    - use_pca: æ˜¯å¦ä½¿ç”¨PCAé™ç»´\n",
    "    - n_components: PCAé™ç»´åçš„ç»´åº¦\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”§ å‡†å¤‡THUCNewså°æ ·æœ¬æ•°æ®é›† (æ ·æœ¬æ•°: {sample_size})...\")\n",
    "\n",
    "    # æ£€æŸ¥æ ·æœ¬æ•°é‡\n",
    "    if len(texts) < sample_size:\n",
    "        print(f\"âš ï¸  å¯ç”¨æ ·æœ¬æ•°({len(texts)})å°äºè¯·æ±‚çš„æ ·æœ¬æ•°({sample_size})\")\n",
    "        sample_size = len(texts)\n",
    "    \n",
    "    # 1. å¹³è¡¡é‡‡æ ·\n",
    "    label_array = np.array(labels)    # è½¬æ¢æˆnp,æ–¹ä¾¿åç»­çš„å¤„ç†\n",
    "    samples_per_class = sample_size // len(categories)\n",
    "    print(f\"æ¯ç±»æ ·æœ¬æ•°: {samples_per_class}\")\n",
    "\n",
    "    selected_texts = []\n",
    "    selected_labels = []\n",
    "\n",
    "    for category in categories:\n",
    "        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰ç´¢å¼•\n",
    "        indices = np.where(label_array == category)[0]\n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            print(f\"âš ï¸  ç±»åˆ« '{category}' æ²¡æœ‰æ ·æœ¬\")\n",
    "            continue\n",
    "        \n",
    "        # éšæœºé€‰å–æ ·æœ¬\n",
    "        if len(indices) > samples_per_class:\n",
    "            selected_indices = np.random.choice(indices, samples_per_class, replace=False)\n",
    "        else:\n",
    "            selected_indices = indices\n",
    "        \n",
    "        for idx in selected_indices:\n",
    "            selected_texts.append(texts[idx])\n",
    "            selected_labels.append(labels[idx])\n",
    "    \n",
    "    print(f\"å¹³è¡¡é‡‡æ ·åæ ·æœ¬æ•°: {len(selected_texts)}\")\n",
    "\n",
    "    # 2. æ ‡ç­¾ç¼–ç \n",
    "    print(\"\\nğŸ·ï¸  ç¼–ç æ ‡ç­¾...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(selected_labels)\n",
    "    class_mapping = {i: class_name for i, class_name in enumerate(label_encoder.classes_)}\n",
    "    print(f\"ç±»åˆ«æ˜ å°„: {class_mapping}\")\n",
    "\n",
    "    # 3. æ–‡æœ¬é¢„å¤„ç†\n",
    "    X_processed = batch_preprocess_texts(selected_texts)\n",
    "\n",
    "    # 4. ç‰¹å¾æå–\n",
    "    print(f\"\\nğŸ“Š è¿›è¡Œæ–‡æœ¬ç‰¹å¾æå– ({feature_type.upper()})...\")\n",
    "    if feature_type == 'tfidf':\n",
    "        # (?u)ï¼šUnicodeæ¨¡å¼\n",
    "        # \\bï¼šå•è¯è¾¹ç•Œ\n",
    "        # [\\u4e00-\\u9fa5]ï¼šåŒ¹é…æ‰€æœ‰ä¸­æ–‡å­—ç¬¦\n",
    "        # +ï¼šä¸€ä¸ªæˆ–å¤šä¸ª\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            lowercase=False,    # ä¸­æ–‡ä¸éœ€è¦å¤§å°å†™\n",
    "            min_df=3,       # å¢åŠ æœ€å°æ–‡æ¡£é¢‘ç‡ï¼Œè¿‡æ»¤ç½•è§è¯\n",
    "            max_df=0.9,     # é™ä½æœ€å¤§æ–‡æ¡£é¢‘ç‡\n",
    "            token_pattern=r'(?u)\\b[\\u4e00-\\u9fa5]+\\b',\n",
    "            use_idf=True\n",
    "        )\n",
    "    elif feature_type == 'count':\n",
    "        vectorizer = CountVectorizer(\n",
    "            max_features=max_features,\n",
    "            lowercase=False,\n",
    "            min_df=3\n",
    "        )\n",
    "    \n",
    "    # æ‹Ÿåˆ\n",
    "    X_features = vectorizer.fit_transform(X_processed)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    print(f\"ç‰¹å¾æå–åå½¢çŠ¶: {X_features.shape}\")\n",
    "    print(f\"è¯æ±‡è¡¨å¤§å°: {len(feature_names)}\")\n",
    "    \n",
    "    # 5. ç¨ å¯†çŸ©é˜µ\n",
    "    print(\"\\nğŸ”„ è½¬æ¢ä¸ºç¨ å¯†çŸ©é˜µ...\")\n",
    "    X_dense = X_features.toarray()\n",
    "    print(f\"ç¨ å¯†çŸ©é˜µå½¢çŠ¶: {X_dense.shape}\")\n",
    "\n",
    "    # 6. æ•°æ®æ ‡å‡†åŒ–\n",
    "    print(\"\\nğŸ“Š æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "    scaler = StandardScaler(with_mean=False)  # ç¨€ç–æ•°æ®ä½¿ç”¨with_mean=False\n",
    "    X_scaled = scaler.fit_transform(X_dense)\n",
    "    print(f\"æ ‡å‡†åŒ–åå½¢çŠ¶: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5e7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cnt = len(np.unique(train_labels_np))\n",
    "label_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9085e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
